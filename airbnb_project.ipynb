{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Project\n",
    "\n",
    "\n",
    "# _An Analysis of AirBnB Listings in London_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Contents_\n",
    "\n",
    "- [Project Plan](#section-1)\n",
    "    - [The Data](#section-1-1)\n",
    "        - [Data Source](#section-1-1-1)\n",
    "        - [Data Content](#section-1-1-2)\n",
    "        - [Data Quality](#section-1-1-3)\n",
    "    - [Project Aims and Objectives](#section-1-2)\n",
    "        - [Objective 1: Predictors of Price and Review Score](#section-1-2-1)\n",
    "        - [Objective 2: Mapping the Distributions of Listings](#section-1-2-2)\n",
    "        - [Objective 3: The Language of Short-Term Rentals](#section-1-2-3)\n",
    "    - [System Design](#section-1-3)\n",
    "        - [Architecture](#section-1-3-1)\n",
    "        - [Processing Modules and Algorithms](#section-1-3-2)\n",
    "* [Program Code](#section-2)\n",
    "    - [Importing Packages](#section-2-1)\n",
    "    - [Data Engineering](#section-2-2)\n",
    "        - [Raw Data Extraction](#section-2-2-1)\n",
    "        - [Fixing Boolean Columns](#section-2-2-2)\n",
    "        - [Fixing Cost Columns](#section-2-2-3)\n",
    "    - [Data Enhancement](#section-2-3)\n",
    "        - [Feature Selection](#section-2-3-1)\n",
    "        - [Distance From Centre](#section-2-3-2)\n",
    "        - [Price Per Bedroom](#section-2-3-3)\n",
    "        - [Amenities Count](#section-2-3-4)\n",
    "        - [Room Type To Entire Property](#section-2-3-5)\n",
    "    - [Data Analysis](#section-2-4)\n",
    "        - [Numerical Outliers](#section-2-4-1)\n",
    "        - [Word Count Outliers](#section-2-4-2)\n",
    "        - [Borough Aggregation](#section-2-4-3)\n",
    "    - [Preparing Visualisations](#section-2-5)\n",
    "        - [Sorted Correlation Heatmaps (Objective 1)](#section-2-5-1)\n",
    "        - [Mapping with Style (Objective 2)](#section-2-5-2)\n",
    "        - [Concentric Circles (Objective 2)](#section-2-5-3)\n",
    "        - [Circle Map (Objective 2)](#section-2-5-4)\n",
    "        - [Generating Word Clouds (Objective 3)](#section-2-5-5)\n",
    "- [Project Outcome](#section-3)\n",
    "    - [Overview of Results](#section-3-1)\n",
    "    - [Objective 1: Predictors of Price and Review Score](#section-3-2)\n",
    "        - [Explanation](#section-3-2-1)\n",
    "        - [Visualisation](#section-3-2-2)\n",
    "    - [Objective 2: Mapping the Distributions of Listings](#section-3-3)\n",
    "        - [Explanation](#section-3-3-1)\n",
    "        - [Visualisation](#section-3-3-2)\n",
    "    - [Objective 3: The Language of Short-Term Rentals](#section-3-4)\n",
    "        - [Explanation](#section-3-4-1)\n",
    "        - [Visualisation](#section-3-4-2)\n",
    "* [Conclusion and Presentation](#section-4)\n",
    "    - [Achievements](#section-4-1)\n",
    "    - [Limitations](#section-4-2)\n",
    "    - [Future Work](#section-4-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Project Plan</u> <a class=\"anchor\" id=\"section-1\"></a>\n",
    "\n",
    "The popularity of AirBnB has transformed the landscape of short-term rentals, offering travelers accommodation and hosts an opportunity for supplementary income. This data science project delves into the dynamics of AirBnB listings in London.\n",
    "\n",
    "## The Data <a class=\"anchor\" id=\"section-1-1\"></a>\n",
    "\n",
    "### Data Source <a class=\"anchor\" id=\"section-1-1-1\"></a>\n",
    "\n",
    "To identify a suitable dataset for this project, I initially searched through the Kaggle.com data catalogue. There, I discovered that a user had uploaded London AirBnB listing data extracted from the web on November 6, 2023. While this was promising, the static nature of the data presented a potential challenge.\n",
    "\n",
    "Examining the source information provided by the user I discovered that the London listings data was being web-scraped by a site called ___Inside AirBnB___ on a monthly basis: http://insideairbnb.com/get-the-data.\n",
    "\n",
    "I've been actively working with the dataset obtained on September 6, 2023. However, my objective for this project is to ensure repeatability. So, one year from now, the code can be re-executed to assess the current state of the market and track its evolution.\n",
    "\n",
    "### Data Content <a class=\"anchor\" id=\"section-1-1-2\"></a>\n",
    "\n",
    "There are two datasets from ___Inside AirBnB___ that we are going to use:\n",
    "\n",
    "___Listings Data___\n",
    "\n",
    "URL: http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/data/listings.csv.gz\n",
    "\n",
    "This csv contains the all the London listings as at 2023-09-06. I've prepared a dictionary of all the columns and their data types in a code cell below. However, we will only be including a subset of those in our analysis.\n",
    "\n",
    "In the following table I highlight a few columns that will be the focus of the analysis:\n",
    "\n",
    "| Column Name | Type | Description |\n",
    "| --- | --- | --- |\n",
    "| price | string | The cost per night of the listing |\n",
    "| neighbourhood_cleansed | string | The London borough in which the listing sits |\n",
    "| latitude , longitude | float | The exact coordinates of the listing |\n",
    "| beds | integer |  The number of beds on the listing |\n",
    "| review_scores_rating | float | The overall rating score from the listing |\n",
    "| review_scores_* | float | 6 columns breaking down the overall rating |\n",
    "| description | string | The text entered by the host to describe and market the property |\n",
    "| amenities | string | Reading this in as a string but it's a list of amenities on a property |\n",
    "| calculated_host_listings_count | integer | Number of listings owned by the host. Calculated from this dataset |\n",
    "\n",
    "<br>\n",
    "\n",
    "___Neighbourhood geojson___\n",
    "\n",
    "URL: \"http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/visualisations/neighbourhoods.geojson\"\n",
    "\n",
    "This is a geojson file that contains the shapes of each of the 32 London boroughs.\n",
    "\n",
    "| Column Name | Type | Description |\n",
    "| --- | --- | --- |\n",
    "| neighbourhood | string | Name of the Borough |\n",
    "| neighbourhood_group | string | Always Null |\n",
    "| geometry | MultiPolygon | The boundary of the borough to be used to draw the outline. |\n",
    "\n",
    "<br>\n",
    "\n",
    "_See below the full list of columns and data types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_data_types = {\n",
    "    \"id\": \"int64\",\n",
    "    \"listing_url\": \"string\",\n",
    "    \"scrape_id\": \"int64\",\n",
    "    \"last_scraped\": \"datetime\",\n",
    "    \"source\": \"string\",\n",
    "    \"name\": \"string\",\n",
    "    \"description\": \"string\",\n",
    "    \"neighborhood_overview\": \"string\",\n",
    "    \"picture_url\": \"string\",\n",
    "    \"host_id\": \"int64\",\n",
    "    \"host_url\": \"string\",\n",
    "    \"host_name\": \"string\",\n",
    "    \"host_since\": \"datetime\",\n",
    "    \"host_location\": \"string\",\n",
    "    \"host_about\": \"string\",\n",
    "    \"host_response_time\": \"category\",\n",
    "    \"host_response_rate\": \"string\",\n",
    "    \"host_acceptance_rate\": \"string\",\n",
    "    \"host_is_superhost\": \"string\",\n",
    "    \"host_thumbnail_url\": \"string\",\n",
    "    \"host_picture_url\": \"string\",\n",
    "    \"host_neighbourhood\": \"category\",\n",
    "    \"host_listings_count\": \"float64\",\n",
    "    \"host_total_listings_count\": \"float64\",\n",
    "    \"host_verifications\": \"string\",\n",
    "    \"host_has_profile_pic\": \"string\",\n",
    "    \"host_identity_verified\": \"string\",\n",
    "    \"neighbourhood\": \"category\",\n",
    "    \"neighbourhood_cleansed\": \"category\",\n",
    "    \"neighbourhood_group_cleansed\": \"category\",\n",
    "    \"latitude\": \"float64\",\n",
    "    \"longitude\": \"float64\",\n",
    "    \"property_type\": \"category\",\n",
    "    \"room_type\": \"category\",\n",
    "    \"accommodates\": \"int64\",\n",
    "    \"bathrooms\": \"float64\",\n",
    "    \"bathrooms_text\": \"string\",\n",
    "    \"bedrooms\": \"float64\",\n",
    "    \"beds\": \"float64\",\n",
    "    \"amenities\": \"string\",\n",
    "    \"price\": \"string\",\n",
    "    \"minimum_nights\": \"int64\",\n",
    "    \"maximum_nights\": \"int64\",\n",
    "    \"minimum_minimum_nights\": \"float64\",\n",
    "    \"maximum_minimum_nights\": \"float64\",\n",
    "    \"minimum_maximum_nights\": \"float64\",\n",
    "    \"maximum_maximum_nights\": \"float64\",\n",
    "    \"minimum_nights_avg_ntm\": \"float64\",\n",
    "    \"maximum_nights_avg_ntm\": \"float64\",\n",
    "    \"calendar_updated\": \"string\",\n",
    "    \"has_availability\": \"string\",\n",
    "    \"availability_30\": \"int64\",\n",
    "    \"availability_60\": \"int64\",\n",
    "    \"availability_90\": \"int64\",\n",
    "    \"availability_365\": \"int64\",\n",
    "    \"calendar_last_scraped\": \"datetime\",\n",
    "    \"number_of_reviews\": \"int64\",\n",
    "    \"number_of_reviews_ltm\": \"int64\",\n",
    "    \"number_of_reviews_l30d\": \"int64\",\n",
    "    \"first_review\": \"datetime\",\n",
    "    \"last_review\": \"datetime\",\n",
    "    \"review_scores_rating\": \"float64\",\n",
    "    \"review_scores_accuracy\": \"float64\",\n",
    "    \"review_scores_cleanliness\": \"float64\",\n",
    "    \"review_scores_checkin\": \"float64\",\n",
    "    \"review_scores_communication\": \"float64\",\n",
    "    \"review_scores_location\": \"float64\",\n",
    "    \"review_scores_value\": \"float64\",\n",
    "    \"license\": \"string\",\n",
    "    \"instant_bookable\": \"string\",\n",
    "    \"calculated_host_listings_count\": \"int64\",\n",
    "    \"calculated_host_listings_count_entire_homes\": \"int64\",\n",
    "    \"calculated_host_listings_count_private_rooms\": \"int64\",\n",
    "    \"calculated_host_listings_count_shared_rooms\": \"int64\",\n",
    "    \"reviews_per_month\": \"float64\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality <a class=\"anchor\" id=\"section-1-1-3\"></a>\n",
    "\n",
    "The dataset is of particular interest for this type of project, as it exhibits both positive and negative aspects concerning its quality. In this project, I aim to harness the positive elements while mitigating the impact of the negatives:\n",
    "\n",
    "___Positives___\n",
    "\n",
    "- This data is highly comprehensive, well-populated and accurate. In fact, it appears to scrape all available information that can be discovered about a listing when exploring the Airbnb website.\n",
    "\n",
    "- The source website routinely scrapes the data. If you set up a pipeline to monitor this, you could expand your dataset or keep it updated with each scrape.\n",
    "\n",
    "- Investigating records within the dataset is easy as a url is provided for each listing. This also increases confidence in the data's reliability, as it's easy to verify correctness on an individual, record-by-record basis.\n",
    "\n",
    "- The dataset encompasses various types of data to explore, including unstructured text entries, location information, numerical values, and categorical data.\n",
    "\n",
    "- Many fields, such as host response rate and review scores, are calculated by Airbnb, ensuring their reliability.\n",
    "\n",
    "\n",
    "___Negatives___\n",
    "\n",
    "- While the columns I'm interested in are well-populated, some columns in the dataset exhibit high null rates.\n",
    "\n",
    "- Portions of the dataset rely on user input, which can introduce issues related to data entry errors and outliers.\n",
    "\n",
    "- Some intriguing property details, like square footage, have been omitted from the dataset.\n",
    "\n",
    "- The dataset contains redundancies, including numerous columns that won't be used in the analysis. I'll be removing these to reduce noise in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Aim and Objectives <a class=\"anchor\" id=\"section-1-2\"></a>\n",
    "\n",
    "This project seeks to offer a comprehensive analysis of Airbnb listings, providing a holistic view of the short-term rental market in London. My goal is to equip both hosts and travellers with valuable insights, enabling them to make informed decisions in this dynamic marketplace.\n",
    "\n",
    "The focus will be on two dimensions: Price and Review score. I will start with a general numerical analysis of factors influencing these dimensions and then dive deeper into the geographical and linguistic factors, using vivid and interesting visualisations to bring the data to life.\n",
    "\n",
    "#### _Objective 1: Numerical Predictors of Price and Review Score_ <a class=\"anchor\" id=\"section-1-2-1\"></a>\n",
    "\n",
    "This objective sets the foundation for our analyses. Using statistical techniques and feature selection I aim to reveal how Price and Review Score correlates with a range of features generated from the data.\n",
    "\n",
    "**Desired Output:** Heatmaps displaying the correllation of the dataset features with price and review score.\n",
    "\n",
    "#### Objective 2: _Mapping the Distributions of Listings_ <a class=\"anchor\" id=\"section-1-2-2\"></a>\n",
    "\n",
    "Utilising mapping and visualization, I will analyse the distribution of listings, discerning patterns in pricing and review scores across London. These insights will guide travelers and hosts in choosing the most suitable locations and properties.\n",
    "\n",
    "**Desired Output:** Visualisations showing the difference in density, price and review scores across London boroughs and how these factors change as you move away from the centre.\n",
    "\n",
    "#### Objective 3: _The Language of Short-Term Rentals_ <a class=\"anchor\" id=\"section-1-2-3\"></a>\n",
    "\n",
    "Building upon our analysis of pricing and review scores, I explore linguistic strategies employed in marketing Airbnb listings. This objective aims to uncover the language in listings associated with high and low review scores, as well as those used to promote more expensive properties vs cheaper ones.\n",
    "\n",
    "**Desired Output:** Word clouds categorised by price and review score demonstrating the language that correlates with those factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Design <a class=\"anchor\" id=\"section-1-3\"></a>\n",
    "\n",
    "### Architecture <a class=\"anchor\" id=\"section-1-3-1\"></a>\n",
    "\n",
    "The system design will be a common industry standard. \n",
    "\n",
    "1. Starting with a Data Engineering ELT (Extract Load Transform) pipeline. Not to be confused with ETL, the idea is we load in a raw cut of the dataset then once we have it stored in our machine we can do transformations. The transformations at this stage will just be simple data fixes and cleaning of values. \n",
    "\n",
    "2. Then I will move on to enhancement, using the existing features of our dataset to uncover more features to be used in our analyses.\n",
    "\n",
    "3. Next an Analysis piece where any outliers will be handled along with null values or anomalies. Here we will also aggregate and combine our two datasets ready for visualisation.\n",
    "\n",
    "4. Finally I will prepare the visualisations. \n",
    "\n",
    "![image.png](architechture.png)\n",
    "\n",
    "### Processing Modules and Algorithms <a class=\"anchor\" id=\"section-1-3-2\"></a>\n",
    "\n",
    "The most significant tools I will be using throughout this project are as follows:\n",
    "\n",
    "* pandas read and write functionality to capture and store the source data.\n",
    "* Using DataFrame loc to conditionally slice a DataFrame, adjust values or remove outliers.\n",
    "* The haversine formula, used to compute distance between two points on a globe.\n",
    "* Aggregations such as count and mean across boroughs and merging with the borough dataset to map the resulting values.\n",
    "* Lambda functions used to apply a small function to a whole Dataframe.\n",
    "* HTML alignment used to have more control over the position and size of visualisations.\n",
    "\n",
    "<br>\n",
    "\n",
    "# <u>Program Code</u>  <a class=\"anchor\" id=\"section-2\"></a>\n",
    "\n",
    "#### _Importing Packages_ <a class=\"anchor\" id=\"section-2-1\"></a>\n",
    "\n",
    "It is standard practice to import packages at the top of your code to show what dependencies are required to run the file.\n",
    "\n",
    "A couple of the packages we are going to import do not come as standard with Anaconda so I have provided a code snippet to pip install here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install geopandas\n",
    "%pip install folium\n",
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have provided some more detail about the use of each package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General purpose data analysis libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import functools\n",
    "\n",
    "# For statistical and numerical plotting (Objective 1)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For plotting maps and handling spacial data (Objective 2)\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import FastMarkerCluster\n",
    "import geopandas\n",
    "\n",
    "# Used to generate Word Clouds and handle text data (Objective 3)\n",
    "import string\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Used to have more control when displaying visualisations \n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preference I set the max_columns option so that I can scroll across all the columns without them being truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Data Engineering <a class=\"anchor\" id=\"section-2-2\"></a>\n",
    "\n",
    "#### _Raw Data Extraction_ <a class=\"anchor\" id=\"section-2-2-1\"></a>\n",
    "\n",
    "The goal for this section is to connect to our data source, pull in the required data and store a copy in our local files.\n",
    "\n",
    "With the column_data_types dictionary I produced during my initial analysis I can read in the raw dataset. However there is a small change I would like to make to separate out date columns. This will allow me to pass the dictionary in as an argument and a list of date columns in as another parse_dates argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Column Type Dict Length: {len(column_data_types)}\")\n",
    "\n",
    "date_columns = []\n",
    "for col, dtype in column_data_types.items():\n",
    "    if dtype == \"datetime\":\n",
    "        date_columns.append(col)\n",
    "\n",
    "for column in date_columns:\n",
    "    column_data_types.pop(column)\n",
    "\n",
    "print(f\"New Column Type Dict Length: {len(column_data_types)}\")\n",
    "print(f\"Date Column List Length: {len(date_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have these separated we can now use pandas to extract the data from the source in the data directory. This code cell uses the url of the csv so that this is repeatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\n",
    "    \"http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/data/listings.csv.gz\", \n",
    "    dtype=column_data_types, \n",
    "    parse_dates=date_columns\n",
    "    )\n",
    "\n",
    "print(f\"DataFrame Shape: {raw_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data loaded with the expected number of records we can store it in a file. I am going to use parquet as storing in csv format can cause issues with our data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_parquet(\"listings.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do the same with the boroughs.geojson file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = geopandas.read_file(\"http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/visualisations/neighbourhoods.geojson\")\n",
    "boroughs.to_file(\"boroughs.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the E and L of the data pipeline is complete with the desired result. We can connect to the source and pull the two datasets into files on our machine. In a more scaled up approach this might into an S3 Bucket or database but this is fine for our project. \n",
    "\n",
    "Now we have a repeatable way of loading our 2 key datasets into our file with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df = pd.read_parquet(\"listings.parquet\")\n",
    "boroughs_geo = geopandas.read_file(\"boroughs.geojson\")\n",
    "\n",
    "print(f\"Listings Shape: {listings_df.shape}\")\n",
    "print(f\"Boroughs Shape: {boroughs_geo.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### _Fixing Boolean Columns_ <a class=\"anchor\" id=\"section-2-2-2\"></a>\n",
    "\n",
    "This section will fix an issue with in this dataset with columns that should be Boolean being set to \"t\" and \"f\" rather than True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = [\n",
    "    'instant_bookable',\n",
    "    'has_availability',\n",
    "    'host_has_profile_pic',\n",
    "    'host_identity_verified',\n",
    "    'host_is_superhost'\n",
    "]\n",
    "display(listings_df[bool_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the True and False values are stored as t and f in the dataset. This is understood as a string by Pandas which doesn't reflect the underlying value in the listing.\n",
    "\n",
    "The aim is to change these values to 1 or 0 and cast as a float which will allow them to be used for correlation later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bool_columns:\n",
    "    listings_df.loc[listings_df[col] == \"t\", col] = \"1\"\n",
    "    listings_df.loc[listings_df[col] == \"f\", col] = \"0\"\n",
    "    listings_df[col] = listings_df[col].astype(float)\n",
    "display(listings_df[bool_columns].head())\n",
    "print(f\"Listings Shape: {listings_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how now t has become 1.0 and f has become 0.0 which has resolved this data issue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Fixing Cost Columns_ <a class=\"anchor\" id=\"section-2-2-3\"></a>\n",
    "\n",
    "Next we will look at an issue with the price column. We are looking at it as a list to make it easy to add future columns if they appear in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_columns = [\n",
    "    \"price\"\n",
    "]\n",
    "display(listings_df[cost_columns+[\"listing_url\"]].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing out this column we see that the issue is that the values contain $ and , characters inside the cost which is preventing them from being cast as float values and therefore preventing any numerical analysis. \n",
    "\n",
    "This is also an issue due to the currency symbol being incorrect. If you check these listings for example index 0 has a price per night of £42 and hour not $42. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cost_columns:\n",
    "    listings_df[col] = listings_df[col].str.replace(\"\\$|,\", \"\", regex=True)\n",
    "    listings_df[col] = listings_df[col].astype(float)\n",
    "display(listings_df[cost_columns+[\"listing_url\"]].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing and recasting has fixed this issue. Now price is a numerical value that we can analyse as such.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Data Enhancement <a class=\"anchor\" id=\"section-2-3\"></a>\n",
    "\n",
    "#### _Feature Selection_ <a class=\"anchor\" id=\"section-2-3-1\"></a>\n",
    "\n",
    "Due to the breadth of this dataset there are many columns which will not be of use during this project. To reduce the noise in the dataset I will specify in a list the columns that I will use and leave the remaining ones out. However, if the requirement come later down the line to use these columns they can easily be added here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = [\n",
    "    # \"id\",\n",
    "    \"listing_url\",\n",
    "    # \"scrape_id\",\n",
    "    # \"source\",\n",
    "    \"name\",\n",
    "    \"description\",\n",
    "    # \"neighborhood_overview\",\n",
    "    # \"picture_url\",\n",
    "    # \"host_id\",\n",
    "    # \"host_url\",\n",
    "    # \"host_name\",\n",
    "    # \"host_location\",\n",
    "    # \"host_about\",\n",
    "    \"host_response_time\",\n",
    "    \"host_response_rate\",\n",
    "    \"host_acceptance_rate\",\n",
    "    \"host_is_superhost\",\n",
    "    # \"host_thumbnail_url\",\n",
    "    # \"host_picture_url\",\n",
    "    # \"host_neighbourhood\",\n",
    "    # \"host_listings_count\",\n",
    "    \"host_total_listings_count\",\n",
    "    # \"host_verifications\",\n",
    "    \"host_has_profile_pic\",\n",
    "    \"host_identity_verified\",\n",
    "    # \"neighbourhood\",\n",
    "    \"neighbourhood_cleansed\",\n",
    "    # \"neighbourhood_group_cleansed\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"property_type\",\n",
    "    \"room_type\",\n",
    "    # \"accommodates\",\n",
    "    # \"bathrooms\",\n",
    "    \"bathrooms_text\",\n",
    "    # \"bedrooms\",\n",
    "    \"beds\",\n",
    "    \"amenities\",\n",
    "    \"price\",\n",
    "    # \"minimum_nights\",\n",
    "    # \"maximum_nights\",\n",
    "    # \"minimum_minimum_nights\",\n",
    "    # \"maximum_minimum_nights\",\n",
    "    # \"minimum_maximum_nights\",\n",
    "    # \"maximum_maximum_nights\",\n",
    "    # \"minimum_nights_avg_ntm\",\n",
    "    # \"maximum_nights_avg_ntm\",\n",
    "    # \"calendar_updated\",\n",
    "    # \"has_availability\",\n",
    "    # \"availability_30\",\n",
    "    # \"availability_60\",\n",
    "    # \"availability_90\",\n",
    "    # \"availability_365\",\n",
    "    \"number_of_reviews\",\n",
    "    \"number_of_reviews_ltm\",\n",
    "    # \"number_of_reviews_l30d\",\n",
    "    \"review_scores_rating\",\n",
    "    \"review_scores_accuracy\",\n",
    "    \"review_scores_cleanliness\",\n",
    "    \"review_scores_checkin\",\n",
    "    \"review_scores_communication\",\n",
    "    \"review_scores_location\",\n",
    "    \"review_scores_value\",\n",
    "    # \"license\",\n",
    "    \"instant_bookable\",\n",
    "    \"calculated_host_listings_count\",\n",
    "    # \"calculated_host_listings_count_entire_homes\",\n",
    "    # \"calculated_host_listings_count_private_rooms\",\n",
    "    # \"calculated_host_listings_count_shared_rooms\",\n",
    "    \"reviews_per_month\"\n",
    "]\n",
    "listings_df = listings_df[select_columns]\n",
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this feature set as a baseline we can now start to think about enhancement.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### _Distance From the Centre_ <a class=\"anchor\" id=\"section-2-3-2\"></a>\n",
    "\n",
    "The Listings DataFrame contains coordinates for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df[[\"listing_url\", \"latitude\", \"longitude\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information is useful on it's own but it would be good to have a single datapoint that measures how close the listing is to the centre of London. This means we need to choose a centre point. This is a question with seemingly no right answer but after doing research I found this article which gave coordinates of the exact centre of London based on geographic measurements:\n",
    "\n",
    "https://www.standard.co.uk/news/london/london-s-real-centre-point-is-next-to-bench-on-the-victoria-embankment-by-the-thames-9381800.html\n",
    "\n",
    "The article gives these coordinates: 51°30’37.6”N 0°06’56.3”W\n",
    "\n",
    "<iframe src=\"https://www.google.com/maps/embed?pb=!1m17!1m12!1m3!1d2483.151070786313!2d-0.11821918763198132!3d51.51044437169647!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m2!1m1!2zNTHCsDMwJzM3LjYiTiAwwrAwNic1Ni4zIlc!5e0!3m2!1sen!2suk!4v1695904951512!5m2!1sen!2suk\" width=\"400\" height=\"300\" style=\"border:0;\" allowfullscreen=\"\" loading=\"lazy\" referrerpolicy=\"no-referrer-when-downgrade\"></iframe>\n",
    "\n",
    "Google Maps has a converter from these northing-westing coordinates to latitude-longitude. We can use this to get the location for the centre of London that we can use throughout our analysis. \n",
    "\n",
    "The lat-long given by Google is 51.510444, -0.115639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTRE_OF_LONDON = (51.510444, -0.115639)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a central location to measure from we need to write a function that can compute the distance between two coordinate points. \n",
    "\n",
    "Since we are dealing with a globe our calculations would be out if we did a simple pythagorean formula; even though it is over a small region. So, we need to calculate the distance between two points on a globe which requires the haversine formula:\n",
    "\n",
    "- https://www.educative.io/answers/how-to-calculate-distance-using-the-haversine-formula\n",
    "\n",
    "Here is my basic implementaion below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(point_a, point_b):\n",
    "    # Unpacking Lat and Longs\n",
    "    lat_a, lon_a = point_a\n",
    "    lat_b, lon_b = point_b\n",
    "    R = 6371  # radius of earth in km\n",
    "    lat_delta = math.radians(lat_b - lat_a)\n",
    "    lon_delta = math.radians(lon_b - lon_a)\n",
    "    a = (math.sin(lat_delta / 2) ** 2) + math.cos(math.radians(lat_a)) * math.cos(math.radians(lat_b)) * math.sin(lon_delta / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c  # distance in km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply this function to our full dataset to compare the distance of each listing to the centre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df[\"distance_from_centre_km\"] = listings_df[[\"latitude\", \"longitude\"]].apply(\n",
    "    lambda row: haversine(CENTRE_OF_LONDON, (row['latitude'], row['longitude'])), \n",
    "    axis=1\n",
    ")\n",
    "listings_df[[\"listing_url\", \"latitude\", \"longitude\", \"distance_from_centre_km\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more interesting thing to add would be distance from centre on the North/South axis and East/West axis. For our purposes, having these in radians is fine as we will only be using them for correlations as opposed to precise mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df[\"distance_from_centre_N\"] = listings_df[\"latitude\"] - CENTRE_OF_LONDON[0]\n",
    "listings_df[\"distance_from_centre_S\"] = CENTRE_OF_LONDON[0] - listings_df[\"latitude\"]\n",
    "listings_df[\"distance_from_centre_E\"] = listings_df[\"longitude\"] - CENTRE_OF_LONDON[1]\n",
    "listings_df[\"distance_from_centre_W\"] = CENTRE_OF_LONDON[1] - listings_df[\"longitude\"]\n",
    "\n",
    "compass_differences = [\"distance_from_centre_N\", \"distance_from_centre_S\", \"distance_from_centre_E\", \"distance_from_centre_W\"]\n",
    "\n",
    "for col in compass_differences:\n",
    "    listings_df.loc[listings_df[col] < 0, col] = np.NaN\n",
    "    listings_df[col].astype(float).apply(math.radians)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now added 5 more features to our dataset which will give us more ways to analyse the listings based on their location.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### _Price Per Bedroom_ <a class=\"anchor\" id=\"section-2-3-3\"></a>\n",
    "\n",
    "An AirBnB listing displays the price for renting per night and this is reflected in our dataset. This is misleading as there might be one property with a single bedroom that costs the same as a property with 10 bedrooms. The current price column would suggest that these properties were equivalent but that would realistically be covering up the fact that one could house many more guests. \n",
    "\n",
    "Thus, I will create a new price_per_bed column to create a price feature that is less dependant on number of beds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df[\"price_per_bed\"] = listings_df[\"price\"]/listings_df[\"beds\"]\n",
    "listings_df[[\"price_per_bed\", \"price\", \"beds\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a price per night per bed metric which will give a better representation of the price of a listing.\n",
    "\n",
    "#### _Amenities Count_ <a class=\"anchor\" id=\"section-2-3-4\"></a>\n",
    "\n",
    "At the moment the amenities column is hard to gain any meaningful insights from as it's just a list of the names of the amenities on the listing. We can use string splitting to give us another numerical column with the number of listings that can be used for the correlation heatmap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df[\"amenities_count\"] = listings_df[\"amenities\"].apply(lambda x: len(list(x.split(\", \"))))\n",
    "\n",
    "pd.options.display.max_colwidth = 300\n",
    "display(listings_df[[\"listing_url\", \"amenities\", \"amenities_count\"]].head())\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Room Type to Entire Property_ <a class=\"anchor\" id=\"section-2-3-5\"></a>\n",
    "\n",
    "Doing some further checks on room type can allow us to infer another boolean field: Whether the listing is for the entire property or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df[\"room_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining these room types it's easy to see that a Property is either an Entire Property or some type of single room, either a room, shared room or hotel room. It will be interesting to turn this into a numerical representation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
